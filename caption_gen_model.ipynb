{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 40 images, renamed them, and copied them to dataset/cat/selected_images\n",
      "Selected 40 images, renamed them, and copied them to dataset/dog/selected_images\n",
      "Selected 40 images, renamed them, and copied them to dataset/swan/selected_images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def select_and_rename_image_files(path, num_images, label):\n",
    "    # List all files in the directory\n",
    "    all_files = os.listdir(path)\n",
    "\n",
    "    # Filter only image files (assuming they have extensions like .jpg, .jpeg, .png, .bmp, .gif)\n",
    "    image_files = [f for f in all_files if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif'))]\n",
    "\n",
    "    # Randomly select the specified number of images\n",
    "    selected_images = random.sample(image_files, num_images)\n",
    "\n",
    "    # Define the path to the new directory\n",
    "    selected_path = os.path.join(path, \"selected_images\")\n",
    "\n",
    "    # Create the directory if it doesn't exist, or clear it if it does\n",
    "    if os.path.exists(selected_path):\n",
    "        shutil.rmtree(selected_path)\n",
    "    os.makedirs(selected_path, exist_ok=True)\n",
    "\n",
    "    # Copy and rename the selected images to the new directory\n",
    "    for i, image in enumerate(selected_images, start=1):\n",
    "        new_filename = f\"{i}_{label}.jpg\"\n",
    "        shutil.copy(os.path.join(path, image), os.path.join(selected_path, new_filename))\n",
    "\n",
    "    print(f\"Selected {len(selected_images)} images, renamed them, and copied them to {selected_path}\")\n",
    "\n",
    "# Apply the function to each dataset\n",
    "datasets = [(\"dataset/cat\", \"cat\"), (\"dataset/dog\", \"dog\"), (\"dataset/swan\", \"swan\")]\n",
    "for dataset_path, label in datasets:\n",
    "    select_and_rename_image_files(dataset_path, 40, label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "import pandas as pd\n",
    "\n",
    "def generate_captions_for_dataset(dataset_name, base_path=\"dataset\", num_images=40):\n",
    "    dataset_path = os.path.join(base_path, dataset_name)\n",
    "    captions_path = os.path.join(base_path, f\"{dataset_name}_captions\")\n",
    "    os.makedirs(captions_path, exist_ok=True)\n",
    "\n",
    "    # List all files in the directory\n",
    "    all_files = os.listdir(dataset_path)\n",
    "\n",
    "    # Filter only image files (assuming they have extensions like .jpg, .jpeg, .png, .bmp, .gif)\n",
    "    image_files = [f for f in all_files if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif'))]\n",
    "\n",
    "    # Randomly select num_images images\n",
    "    selected_images = random.sample(image_files, num_images)\n",
    "\n",
    "    # Load the processor and model\n",
    "    processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "\n",
    "\n",
    "    model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-large\")\n",
    "\n",
    "    captions = []\n",
    "\n",
    "    for image_file in selected_images:\n",
    "        # Load and preprocess the image\n",
    "        image_path = os.path.join(dataset_path, image_file)\n",
    "        raw_image = Image.open(image_path).convert(\"RGB\")  # Ensure the image is in RGB mode\n",
    "\n",
    "        # Generate caption with minimum and maximum length settings\n",
    "        inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            min_length=25,  # Set a minimum length to encourage longer captions\n",
    "            max_length=100,  # Set a maximum length to avoid excessively long captions\n",
    "            num_beams=5,  # Use beam search to improve the quality of the generated caption\n",
    "            no_repeat_ngram_size=2,  # Avoid repeating n-grams of the specified size\n",
    "            early_stopping=True  # Stop early when the end token is generated\n",
    "        )\n",
    "\n",
    "        caption = processor.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "        # # Ensure the caption has exactly 20 words, adjusting if necessary\n",
    "        # words = caption.split()\n",
    "        # if len(words) > 20:\n",
    "        #     caption = ' '.join(words[:20])\n",
    "        # elif len(words) < 20:\n",
    "        #     # Optionally, pad with additional words or symbols if less than 20\n",
    "        #     caption = ' '.join(words + ['<pad>'] * (20 - len(words)))\n",
    "\n",
    "        # Store the caption with its corresponding image file name\n",
    "        captions.append({\"image\": image_file, \"caption\": caption})\n",
    "\n",
    "    # Save captions to a CSV file\n",
    "    captions_df = pd.DataFrame(captions)\n",
    "    captions_df.to_csv(os.path.join(captions_path, \"captions.csv\"), index=False)\n",
    "\n",
    "    print(f\"Generated captions for {dataset_name} images and saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated captions for dog/selected_images images and saved to CSV.\n",
      "Generated captions for cat/selected_images images and saved to CSV.\n",
      "Generated captions for swan/selected_images images and saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"dog/selected_images\", \"cat/selected_images\", \"swan/selected_images\"]\n",
    "for dataset in datasets:\n",
    "    generate_captions_for_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
