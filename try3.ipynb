{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from datasets) (1.26.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-16.1.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.5-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from datasets) (0.23.2)\n",
      "Requirement already satisfied: packaging in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from datasets) (6.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from aiohttp->datasets) (22.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from huggingface-hub>=0.21.2->datasets) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from requests>=2.32.2->datasets) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.15.0)\n",
      "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp39-cp39-macosx_11_0_arm64.whl (390 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.7/390.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pyarrow-16.1.0-cp39-cp39-macosx_11_0_arm64.whl (26.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/26.0 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "Downloading pandas-2.2.2-cp39-cp39-macosx_11_0_arm64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading xxhash-3.4.1-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\n",
      "Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp39-cp39-macosx_11_0_arm64.whl (81 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.8/81.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, xxhash, tzdata, tqdm, requests, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, dill, async-timeout, yarl, pandas, multiprocess, aiosignal, aiohttp, datasets\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.1\n",
      "    Uninstalling tqdm-4.66.1:\n",
      "      Successfully uninstalled tqdm-4.66.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.6.0\n",
      "    Uninstalling fsspec-2024.6.0:\n",
      "      Successfully uninstalled fsspec-2024.6.0\n",
      "Successfully installed aiohttp-3.9.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.20.0 dill-0.3.8 frozenlist-1.4.1 fsspec-2024.5.0 multidict-6.0.5 multiprocess-0.70.16 pandas-2.2.2 pyarrow-16.1.0 pyarrow-hotfix-0.6 pytz-2024.1 requests-2.32.3 tqdm-4.66.4 tzdata-2024.1 xxhash-3.4.1 yarl-1.9.4\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: diffusers in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (0.28.0)\n",
      "Requirement already satisfied: transformers in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (4.41.2)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.18.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: importlib-metadata in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from diffusers) (6.0.0)\n",
      "Requirement already satisfied: filelock in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from diffusers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.2 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from diffusers) (0.23.2)\n",
      "Requirement already satisfied: numpy in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from diffusers) (1.26.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from diffusers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from diffusers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from diffusers) (0.4.3)\n",
      "Requirement already satisfied: Pillow in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from diffusers) (10.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from transformers) (4.66.4)\n",
      "Collecting torch==2.3.1 (from torchvision)\n",
      "  Downloading torch-2.3.1-cp39-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from torch==2.3.1->torchvision) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from torch==2.3.1->torchvision) (1.12.1)\n",
      "Requirement already satisfied: networkx in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from torch==2.3.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from torch==2.3.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from torch==2.3.1->torchvision) (2024.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from importlib-metadata->diffusers) (3.15.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from requests->diffusers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from requests->diffusers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from requests->diffusers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from requests->diffusers) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from jinja2->torch==2.3.1->torchvision) (2.1.2)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /Users/lixiaozao/Library/Python/3.9/lib/python/site-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.18.1-cp39-cp39-macosx_11_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.3.1-cp39-none-macosx_11_0_arm64.whl (61.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.3.0\n",
      "    Uninstalling torch-2.3.0:\n",
      "      Successfully uninstalled torch-2.3.0\n",
      "Successfully installed torch-2.3.1 torchvision-0.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install diffusers transformers torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'concatenate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m     test_datasets[category] \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_dict({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: images[\u001b[38;5;241m30\u001b[39m:], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m\"\u001b[39m: captions[\u001b[38;5;241m30\u001b[39m:]})\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Concatenate train datasets into one\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m DatasetDict({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mtrain_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m(train_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdog\u001b[39m\u001b[38;5;124m'\u001b[39m], train_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mswan\u001b[39m\u001b[38;5;124m'\u001b[39m])})\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Concatenate test datasets into one\u001b[39;00m\n\u001b[1;32m     38\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m DatasetDict({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mconcatenate(test_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdog\u001b[39m\u001b[38;5;124m'\u001b[39m], test_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mswan\u001b[39m\u001b[38;5;124m'\u001b[39m])})\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'concatenate'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import Dataset, DatasetDict\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base path for your datasets\n",
    "base_image_folder = 'dataset'\n",
    "base_caption_folder = 'dataset'\n",
    "\n",
    "# Define categories\n",
    "categories = ['cat', 'dog', 'swan']\n",
    "\n",
    "def load_custom_dataset(base_image_folder, base_caption_folder, category):\n",
    "    image_folder = os.path.join(base_image_folder, category, 'selected_images')\n",
    "    caption_file = os.path.join(base_caption_folder, category, 'selected_images_captions', 'captions.csv')\n",
    "    \n",
    "    data = pd.read_csv(caption_file)\n",
    "    images = [os.path.join(image_folder, img) for img in data['image']]\n",
    "    captions = data['caption'].tolist()\n",
    "    \n",
    "    return images, captions  # Return images and captions as lists\n",
    "\n",
    "# Load datasets for each category\n",
    "train_datasets = {}\n",
    "test_datasets = {}\n",
    "for category in categories:\n",
    "    images, captions = load_custom_dataset(base_image_folder, base_caption_folder, category)\n",
    "    \n",
    "    # Split into train and test (assuming 30 train, 10 test for each category)\n",
    "    train_datasets[category] = Dataset.from_dict({\"image\": images[:30], \"caption\": captions[:30]})\n",
    "    test_datasets[category] = Dataset.from_dict({\"image\": images[30:], \"caption\": captions[30:]})\n",
    "\n",
    "# Concatenate train datasets into one\n",
    "train_dataset = DatasetDict({\"train\": train_datasets['cat'].concatenate(train_datasets['dog'], train_datasets['swan'])})\n",
    "\n",
    "# Concatenate test datasets into one\n",
    "test_dataset = DatasetDict({\"test\": test_datasets['cat'].concatenate(test_datasets['dog'], test_datasets['swan'])})\n",
    "\n",
    "# Preprocess function\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "def transform(examples):\n",
    "    images = [preprocess(Image.open(image).convert(\"RGB\")) for image in examples[\"image\"]]\n",
    "    return {\"image\": images, \"caption\": examples[\"caption\"]}\n",
    "\n",
    "# Apply the transform\n",
    "train_dataset = train_dataset.map(transform, batched=True)\n",
    "test_dataset = test_dataset.map(transform, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import StableDiffusionPipeline\n",
    "from transformers import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = AdamW(pipe.unet.parameters(), lr=5e-6)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataloader = DataLoader(train_dataset[\"train\"], batch_size=4, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        images, captions = batch[\"image\"], batch[\"caption\"]\n",
    "        images = images.to(\"cuda\")\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = pipe(images, captions)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if step % 10 == 0:\n",
    "            print(f\"Epoch {epoch} Step {step} Loss {loss.item()}\")\n",
    "\n",
    "# Save the fine-tuned model\n",
    "pipe.save_pretrained(\"fine-tuned-stable-diffusion\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"fine-tuned-stable-diffusion\", torch_dtype=torch.float16)\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "# Generate images from the test captions for each category\n",
    "generated_images = []\n",
    "test_captions = []\n",
    "for i, category in enumerate(categories):\n",
    "    start_idx = i * 10\n",
    "    end_idx = start_idx + 10\n",
    "    category_test_dataset = test_dataset[\"test\"].select(range(start_idx, end_idx))\n",
    "    \n",
    "    for j, caption in enumerate(category_test_dataset[\"caption\"]):\n",
    "        image = pipe(caption).images[0]\n",
    "        image_path = f\"{category}_generated_image_{j}.png\"\n",
    "        image.save(image_path)\n",
    "        generated_images.append(image_path)\n",
    "        test_captions.append(caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Load the CLIP model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "def calculate_clip_score(image_paths, captions):\n",
    "    clip_scores = []\n",
    "    \n",
    "    for image_path, caption in zip(image_paths, captions):\n",
    "        image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "        text = clip.tokenize([caption]).to(device)\n",
    "\n",
    "        # Calculate feature vectors\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image)\n",
    "            text_features = model.encode_text(text)\n",
    "\n",
    "        # Calculate cosine similarity\n",
    "        cosine_similarity = torch.nn.functional.cosine_similarity(image_features, text_features).item()\n",
    "        clip_scores.append(cosine_similarity)\n",
    "    \n",
    "    return clip_scores\n",
    "\n",
    "# Calculate CLIP scores\n",
    "clip_scores = calculate_clip_score(generated_images, test_captions)\n",
    "print(\"CLIP Scores:\", clip_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import inception_v3\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from PIL import Image\n",
    "\n",
    "# Custom dataset for loading generated images\n",
    "class GeneratedImageDataset(Dataset):\n",
    "    def __init__(self, image_paths):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((299, 299)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        return self.transform(image)\n",
    "\n",
    "def inception_score(image_paths, batch_size=32, splits=10):\n",
    "    dataset = GeneratedImageDataset(image_paths)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Load the InceptionV3 model\n",
    "    inception_model = inception_v3(pretrained=True, transform_input=False).to(device)\n",
    "    inception_model.eval()\n",
    "\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = batch.to(device)\n",
    "            pred = inception_model(batch)\n",
    "            preds.append(F.softmax(pred, dim=1).cpu().numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "\n",
    "    # Compute the Inception Score\n",
    "    split_scores = []\n",
    "    N = preds.shape[0]\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits): (k + 1) * (N // splits), :]\n",
    "        py = np.mean(part, axis=0)\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx, py))\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)\n",
    "\n",
    "# Calculate Inception Score\n",
    "is_mean, is_std = inception_score(generated_images)\n",
    "print(\"Inception Score: Mean =\", is_mean, \"Std =\", is_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
